/**
 * @file pmap.c
 * @desc physical memory allocator
 */
#include <x86.h>
#include <mmu.h>
#include <error.h>
#include <string.h>
#include <assert.h>
#include <kern/pmap.h>
#include <kern/kclock.h>

#ifdef DEBUG
#define PRINTMEM(a, b)                                                  \
  {                                                                     \
    uint32_t _b = (uint32_t) (b);                                       \
    cprintf("%40s = %10u (%08lx)\n", (char *) (a), _b, _b);             \
  }
#else
#define PRINTMEM(a, b) 
#endif


/* variables set by i386_detect_memory() */
static physaddr_t maxpa;    /* maximum physical address */
size_t npage;               /* amount of physical memory (in pages) */
static size_t basemem;      /* amount of base memory (in bytes) */
static size_t extmem;       /* amount of extended memory (in bytes) */

/* variables set in i386_vm_init() */
pde_t *boot_pgdir;          /* virtual address of boot time page directory */
physaddr_t boot_cr3;        /* physical address of boot time page directory */
static char *boot_freemem;  /* pointer to next byte of free mem */
struct page *pages;         /* virtual address of physical page array */
static struct pagelist page_free_list;   /* free list of physical pages */

/* GDT (global descriptor table):
   the kernel and user segments are identical (except for the DPL);
   to load the SS register, the CPL must equal the DPL; thus,
   we must duplicate the segments for the user and the kernel */
struct segdesc gdt[] = {
  /* 0x0 - unused (always faults -- for trapping NULL far pointers) */
  SEG_NULL,

  /* 0x8 - kernel code segment */
  [GD_KT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 0),

  /* 0x10 - kernel data segment */
  [GD_KD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 0),

  /* 0x18 - user code segment */
  [GD_UT >> 3] = SEG(STA_X | STA_R, 0x0, 0xffffffff, 3),

  /* 0x20 - user data segment */
  [GD_UD >> 3] = SEG(STA_W, 0x0, 0xffffffff, 3),

  /* 0x28 - tss, initialized in idt_init() */
  [GD_TSS >> 3] = SEG_NULL
};

struct pseudodesc gdt_pd = {
  sizeof(gdt) - 1, (unsigned long) gdt,
};

static int nvram_read(int r)
{
  return mc146818_read(NULL, r) | (mc146818_read(NULL, r+1) << 8);
}

void i386_detect_memory(void)
{
  /* get base and extended memory size in bytes; nvram_read() returns 
     memory size in KB */
  basemem = ROUNDDOWN(nvram_read(NVRAM_BASELO) * 1024, PGSIZE);
  extmem = ROUNDDOWN(nvram_read(NVRAM_EXTLO) * 1024, PGSIZE);

  /* calculate the maxmium physical address */
  if (extmem)
    maxpa = EXTPHYSMEM + extmem;
  else
    maxpa = basemem;
  npage = maxpa / PGSIZE;

  cprintf("physical memory: %dKB available ", (maxpa >> 10));
  cprintf("(base = %dKB; ext = %dKB, npage = %d)\n", 
          (basemem >> 10), (extmem >> 10), npage);
}

/* set up initial memory mappings and turn on MMU */
static void check_boot_pgdir(void);
static void check_page_alloc();

/* allocate n bytes of physical memory aligned on an align-byte boundary;
   align must be a power of two; return kernel virtual address; returned 
   memory is uninitialized; boot_alloc() should panic on out of memory; 
   however, it's too early to run out of memory

   NOTE: this function may only be used during initialization, before the 
         page_free_list has been set up */
static void *boot_alloc(uint32_t n, uint32_t align)
{
  extern char end[];
  void *v;

  /* initialize boot_freemem if this is the first time; 'end' is a magic 
     symbol automatically generated by the linker, which points to the end 
     of the kernel's bss segment -- i.e. the first virtual address that 
     the linker did *not* assign to any kernel code or global variables
     NOTE: see kern/kernel.ld for details */
  if (boot_freemem == 0)
    boot_freemem = end;
  PRINTMEM("end", end);

  /* round up boot_freemem to be aligned properly */
  boot_freemem = ROUNDUP(boot_freemem, align);
  
  /* save current value of boot_freemem as allocated chunk */
  v = (void *) boot_freemem;

  /* increase boot_freemem to record allocation */
  boot_freemem += n;

  return v;
}

/* given pgdir, a pointer to a page directory, walk the 2-level page table 
   structure to find the page table entry (PTE) for linear address la;
   return a pointer to this PTE; 

   if the relevant page table doesn't exist in the page directory:
   - if create == 0, return 0.
   - otherwise, allocate a new page table, install it into pgdir,
     and return a pointer into it.
     (hint: What should the new page table contain?)
   
   this function abstracts away the 2-level nature of the page directory 
   by allocating new page tables as needed
 
   boot_pgdir_walk cannot fail; it's too early to fail; this function may 
   ONLY be used during initialization, before the page_free_list has been 
   set up */
pte_t *boot_pgdir_walk(pde_t *pgdir, const void *va, int create, pte_t **ppte)
//static pte_t *pgdir_walk(pde_t *pgdir, const void *va, int create)
{
  pde_t *pde = &pgdir[PDX(va)];
  pte_t *pgtab;
  struct page *pp;
  if (*pde & PTE_P)
    pgtab = (pte_t *) PTE_ADDR(*pde);
  else {
    cprintf("create\n");
    if (!create || (pgtab = (pte_t *) page_alloc(&pp)) != 0)
      return 0;
    memset(pgtab, 0, PGSIZE);
    *pde = ((uintptr_t) pgtab << 12) | PTE_P | PTE_W | PTE_U;
  }
  return &pgtab[PTX(va)];
}

/* map [la, la+size) of linear address space to physical [pa, pa+size)
   in the page table rooted at pgdir; size is a multiple of PGSIZE;
   use permission bits perm|PTE_P for the entries

   this function may ONLY be used during initialization, before the
   page_free_list has been set up */
static void boot_map_pages(pde_t *pgdir, uintptr_t la, size_t size, 
                           physaddr_t pa, int perm)
{
  char *addr, *last;
  pte_t *pte;

  /* assert 'pa' is aligned at page boundary */
  assert((pa << 20) == 0x0);

  addr = (char *) ROUNDDOWN(la, 1);
  last = (char *) ROUNDDOWN(la + size - 1, 1);
  for (;;) {
    pte = pgdir_walk(pgdir, addr, 1 /* create */);
    if (pte == 0)
      panic("pgdir_walk");
    if (*pte & PTE_P) 
      panic("remap");
    *pte = pa | perm | PTE_P;
    if (addr == last)
      break;
    addr += PGSIZE;
    pa += PGSIZE;
  }
}


/* set up a two-level page table:
   - boot_pgdir is its linear (virtual) address of the root
   - boot_cr3 is the physical adresss of the root
   then, turn on paging and effectively turn off segmentation
   (i.e., the segment base addrs are set to zero).

   this function only sets up the kernel part of the address space
   (i.e. addresses >= UTOP); the user part of the address space will be 
   setup later; from UTOP to ULIM, the user is allowed to read but not 
   write; above ULIM the user cannot read (or write) */
void i386_vm_init(void)
{
  pde_t *pgdir;
  uint32_t cr0;
  size_t n;

  /* create initial page directory */
  pgdir = boot_alloc(PGSIZE, PGSIZE);
  memset(pgdir, 0, PGSIZE);
  boot_pgdir = pgdir;
  boot_cr3 = PADDR(pgdir);
  PRINTMEM("boot_pgdir", boot_pgdir);
  PRINTMEM("boot_cr3", boot_cr3);
  PRINTMEM("boot_freemem", boot_freemem);

  /* recursively insert PD in itself as a page table, to form a virtual 
     page table at virtual address VPT:
     - VPT; permissions: kernel RW, user NONE
     - UVPT; permissions: kernel R, user R */
  pgdir[PDX(VPT)] = PADDR(pgdir)|PTE_W|PTE_P;
  pgdir[PDX(UVPT)] = PADDR(pgdir)|PTE_U|PTE_P;
  PRINTMEM("VPT", VPT);
  PRINTMEM("PDX(VPT)", PDX(VPT));
  PRINTMEM("PADDR(pgdir)", PADDR(pgdir));
  PRINTMEM("pgdir[PDX(VPT)]", pgdir[PDX(VPT)]);

	/* allocate an array of npage 'struct page's and store it in 'pages';
     the kernel uses this array to keep track of physical pages: for
     each physical page, there is a corresponding struct page in this
     array; 'npage' is the number of physical pages in memory; user-level 
     programs will get read-only access to the array as well */
  pages = (struct page *) boot_alloc(npage * sizeof(struct page), 32);
  PRINTMEM("pages", pages);
  PRINTMEM("boot_freemem", boot_freemem);

	/* now that we've allocated the initial kernel data structures, we set
     up the list of free physical pages; once we've done so, all further
     memory management will go through the page_* functions; in particular, 
     we can now map memory using boot_map_pages() or page_insert() */
  cprintf("+++ page_init: pages check\n");
	page_init();
  cprintf("+++ check_page_alloc: page_alloc/page_free testing\n");
	check_page_alloc();
  cprintf("+++ page_check: \n");
	page_check();

  /* now we set up virtual memory */
  cprintf("+++ vm setup\n");
	
  /* map 'pages' read-only by the user at linear address UPAGES;
     permissions:
       - the new image at UPAGES: kernel R, user R (i.e. perm = PTE_U|PTE_P)
       - pages itself: kernel RW, user NONE */
  //boot_map_pages(pgdir, UPAGES, PADDR(), PTE_U);

	/* use the physical memory that 'bootstack' refers to as the kernel
     stack; the kernel stack grows down from virtual address KSTACKTOP;
     we consider the entire range from [KSTACKTOP-PTSIZE, KSTACKTOP) 
     to be the kernel stack, but break this into two pieces:

     - [KSTACKTOP-KSTKSIZE, KSTACKTOP): backed by physical memory
     - [KSTACKTOP-PTSIZE, KSTACKTOP-KSTKSIZE): not backed; so if
       the kernel overflows its stack, it will fault rather than
       overwrite memory.  Known as a "guard page".

     permissions: kernel RW, user NONE */
  boot_map_pages(pgdir, KSTACKTOP-KSTKSIZE, KSTKSIZE, 0, PTE_W);
  boot_map_pages(pgdir, KSTACKTOP-PTSIZE, PTSIZE-KSTKSIZE, 0, PTE_W);

	/* map all of physical memory at KERNBASE; i.e. the VA range 
     [KERNBASE, 2^32) should map to the PA range [0, 2^32 - KERNBASE);
     we might not have (2^32 - KERNBASE) bytes of physical memory, but
     we just set up the mapping anyway;
     permissions: kernel RW, user NONE */
  boot_map_pages(pgdir, KERNBASE, (2^32)-KERNBASE, 0, PTE_W);

	/* check that the initial page directory has been set up correctly */
	check_boot_pgdir();

	/* on x86, segmentation maps a VA to a LA (linear addr) and paging 
     maps the LA to a PA; i.e. VA => LA => PA; if paging is turned off 
     the LA is used as the PA;
     NOTE: there is no way to turn off segmentation; the closest thing 
     is to set the base address to 0, so VA => LA mapping is the identity */

	/* CURRENT MAPPING: VA KERNBASE + x => PA x;
     (segmentation base = -KERNBASE and paging is off) */

  /* from here on down we must maintain this VA KERNBASE + x => PA x
     mapping, even though we are turning on paging and reconfiguring
     segmentation */

	/* map VA 0:4MB same as VA KERNBASE, i.e. to PA 0:4MB; 
     (limits our kernel to < 4MB) */
	pgdir[0] = pgdir[PDX(KERNBASE)];

	/* install page table */
	lcr3(boot_cr3);

	/* turn on paging */
	cr0 = rcr0();
	cr0 |= CR0_PE|CR0_PG|CR0_AM|CR0_WP|CR0_NE|CR0_TS|CR0_EM|CR0_MP;
	cr0 &= ~(CR0_TS|CR0_EM);
	lcr0(cr0);

	/* CURRENT MAPPING: KERNBASE + x => x => x;
     (x < 4MB so uses paging pgdir[0]) */

	// Reload all segment registers.
	asm volatile("lgdt gdt_pd");
	asm volatile("movw %%ax,%%gs" :: "a" (GD_UD|3));
	asm volatile("movw %%ax,%%fs" :: "a" (GD_UD|3));
	asm volatile("movw %%ax,%%es" :: "a" (GD_KD));
	asm volatile("movw %%ax,%%ds" :: "a" (GD_KD));
	asm volatile("movw %%ax,%%ss" :: "a" (GD_KD));
	asm volatile("ljmp %0,$1f\n 1:\n" :: "i" (GD_KT));  // reload cs
	asm volatile("lldt %%ax" :: "a" (0));

	/* FINAL MAPPING: KERNBASE + x => KERNBASE + x => x;
     this mapping was only used after paging was turned on but before 
     the segment registers were reloaded */
	pgdir[0] = 0;

	/* flush the TLB for good measure, to kill the pgdir[0] mapping */
	lcr3(boot_cr3);

}


/* check the physical page allocator: page_alloc(), page_free(), page_init() */
static void check_page_alloc()
{
	struct page *pp, *pp0, *pp1, *pp2;
	struct pagelist fl;

	/* if there's a page that shouldn't be on the free list, try to make 
     sure it eventually causes trouble */
	LIST_FOREACH(pp0, &page_free_list, pp_link) {
		/* check that we didn't corrupt the free list itself */
		assert((pages <= pp0) && (pp0 < pages + npage));

		/* check a few pages that shouldn't be on the free list */
		assert(page2pa(pp0) != 0);
		assert(page2pa(pp0) != IOPHYSMEM);
		assert(page2pa(pp0) != EXTPHYSMEM - PGSIZE);
		//assert(page2kva(pp0) != ROUNDDOWN(boot_freemem - 1, PGSIZE));
	}

	/* should be able to allocate three pages */
	pp0 = pp1 = pp2 = 0;
	assert(page_alloc(&pp0) == 0);
	assert(page_alloc(&pp1) == 0);
	assert(page_alloc(&pp2) == 0);

	assert(pp0);
	assert(pp1 && pp1 != pp0);
	assert(pp2 && pp2 != pp1 && pp2 != pp0);
	assert(page2pa(pp0) < npage*PGSIZE);
	assert(page2pa(pp1) < npage*PGSIZE);
	assert(page2pa(pp2) < npage*PGSIZE);

	/* temporarily steal the rest of the free pages */
	fl = page_free_list;
	LIST_INIT(&page_free_list);

	/* should be no free memory*/
	assert(page_alloc(&pp) == -E_NO_MEM);

	/* free and re-allocate? */
	page_free(pp0);
	page_free(pp1);
	page_free(pp2);
	pp0 = pp1 = pp2 = 0;
	assert(page_alloc(&pp0) == 0);
	assert(page_alloc(&pp1) == 0);
	assert(page_alloc(&pp2) == 0);
	assert(pp0);
	assert(pp1 && pp1 != pp0);
	assert(pp2 && pp2 != pp1 && pp2 != pp0);
	assert(page_alloc(&pp) == -E_NO_MEM);

	/* give free list back*/
	page_free_list = fl;

	/* free the pages we took */
	page_free(pp0);
	page_free(pp1);
	page_free(pp2);
}


/* checks that the kernel part of virtual address space has been setup 
   roughly correctly (by i386_vm_init()); this function doesn't test 
   every corner case, in fact it doesn't test the permission bits at all,
   but it is a pretty good sanity check */
static physaddr_t check_va2pa(pde_t *pgdir, uintptr_t va);

static void check_boot_pgdir(void)
{
  uint32_t i, n;
  pde_t *pgdir;

  pgdir = boot_pgdir;

  /* check pages array */
  n = ROUNDUP(npage * sizeof(struct page), PGSIZE);
  for (i = 0; i < n; i += PGSIZE)
    assert(check_va2pa(pgdir, UPAGES + i) == PADDR(pages) + i);
  
  /* check phys mem */
  for (i = 0; KERNBASE + i != 0; i += PGSIZE)
    assert(check_va2pa(pgdir, KERNBASE + i) == i);

  /* check kernel stack */
  for (i = 0; i < KSTKSIZE; i += PGSIZE)
    assert(check_va2pa(pgdir, KSTACKTOP-KSTKSIZE+i) == PADDR(bootstack) + i);

	assert(check_va2pa(pgdir, KSTACKTOP - PTSIZE) == ~0);

  /* check for zero/non-zero in PDEs */
  for (i = 0; i < NPDENTRIES; i++) {
    switch (i) {
    case PDX(VPT):
    case PDX(UVPT):
    case PDX(KSTACKTOP-1):
    case PDX(UPAGES):
      assert(pgdir[i]);
      break;
    default:
      if (i >= PDX(KERNBASE))
        assert(pgdir[i]);
      else
        assert(pgdir[i] == 0);
      break;
    }
  }
  cprintf("check_boot_pgdir() succeeded!\n");
}

/* this function returns the physical address of the page containing 'va',
   defined by the page directory 'pgdir'; the hardware normally performs
   this functionality for us; we define our own version to help check
   the check_boot_pgdir() function; it shouldn't be used elsewhere */
static physaddr_t check_va2pa(pde_t *pgdir, uintptr_t va)
{
  pte_t *p;

  pgdir = &pgdir[PDX(va)];
  if (!(*pgdir & PTE_P))
    return ~0;

  p = (pte_t*) KADDR(PTE_ADDR(*pgdir));
  if (!(p[PTX(va)] & PTE_P))
    return ~0;

  return PTE_ADDR(p[PTX(va)]);
}
    
/* tracking of physical pages:
   the 'pages' array has one 'struct page' entry per physical page;
   pages are reference counted, and free pages are kept on a linked list */

/* initialize page structure and memory free list; after this point, ONLY 
   use the functions below to allocate and deallocate physical memory via 
   the page_free_list, and NEVER use boot_alloc() or the related boot-time 
   functions above */
void page_init(void)
{
  struct page *pp0;

  int i;
  physaddr_t page_addr = 0;
  LIST_INIT(&page_free_list);
  for (i = 0; i < npage; i++, page_addr += PGSIZE) {
    pages[i].pp_ref = 0;

    /* mark physical page 0 as in use; this way we preserve the real-mode IDT 
       and BIOS structures in case we ever need them (currently we don't) */
    if (page_addr == 0) continue;
 
    /* mark IO hole [IOPHYSMEM, EXTPHYSMEM); mark it as in use so that it 
       can never be allocated */
    if (page_addr >= IOPHYSMEM && page_addr < EXTPHYSMEM) continue;

    /* pages from ULIM and above, don't add them to free list */
    if (page_addr >= ULIM) continue;

    LIST_INSERT_HEAD(&page_free_list, &pages[i], pp_link);
  }
}

/* initialize a page structure; the result has null links and 0 refcount */
static void page_clear(struct page *pp)
{
  memset(pp, 0, sizeof(*pp));
}

/* allocates a physical page; does NOT clear the contents of the page 
   to zero NOR increase the ref count -- the caller must do that if 
   necessary

   on success, returns 0 and *pp is set to point to the page struct of the 
   newly allocated page; otherwise, returns E_NO_MEM */
int page_alloc(struct page **pp)
{
  *pp = LIST_FIRST(&page_free_list);
  if (!*pp)
    return -E_NO_MEM;

  LIST_REMOVE(*pp, pp_link);
  page_clear(*pp);
  return 0;
}

/* return a page to the free list; this function should only be called 
   when pp->pp_ref reaches 0 */
void page_free(struct page *pp)
{
  assert(pp->pp_ref == 0);
  page_clear(pp);
  LIST_INSERT_HEAD(&page_free_list, pp, pp_link);
}

/* decrement the reference count on a page, freeing it if there are no 
   more refs */
void page_decref(struct page *pp)
{
  if (--pp->pp_ref == 0)
    page_free(pp);
}


/* given 'pgdir', a pointer to a page directory, pgdir_walk returns
   a pointer to the page table entry (PTE) for linear address 'va';
   this requires walking the two-level page table structure

   if the relevant page table doesn't exist in the page directory, then:

     - if create == 0, pgdir_walk returns NULL
     - otherwise, pgdir_walk tries to allocate a new page table

   with page_alloc; if this fails, pgdir_walk returns NULL; in case it
   successfully allocates a page table, 

      - pgdir_walk sets pp_ref to 1 for the new page table.
      - pgdir_walk clears the new page table.
      - finally, pgdir_walk returns a pointer into the new page table.

   HINT: the x86 MMU checks permission bits in both the page directory
   and the page table, so it's safe to leave permissions in the page
   more permissive than strictly necessary */
static pte_t *pgdir_walk(pde_t *pgdir, const void *va, int create)
{
  pde_t *pde = &pgdir[PDX(va)];
  pte_t *pgtab;
  struct page *pp;
  if (*pde & PTE_P) {
    cprintf("pgdir_walk ==> present");
    pgtab = (pte_t *) PTE_ADDR(*pde);
  }
  else {
    cprintf("pgdir_walk ==> create\n");
    if (!create || page_alloc(&pp) != 0) {
      cprintf("pgdir_walk ==> not created (error)\n");
      return 0;
    }
    pgtab = (pte_t *) page2pa(pp);
    memset(pgtab, 0, PGSIZE);
    pp->pp_ref = 1;
    *pde = ((uintptr_t) pgtab << 12) | PTE_P | PTE_W | PTE_U;
  }
  PRINTMEM("pgdir", pgdir);
  PRINTMEM("PDX(va)", PDX(va));
  PRINTMEM("pde", pde);
  PRINTMEM("*pde", *pde);
  PRINTMEM("pgtab", pgtab);
  return &pgtab[PTX(va)];
}

/* map the physical page 'pp' at virtual address 'va'; the permissions 
   (the low 12 bits) of the page table entry should be set to 'perm|PTE_P'

     - if there is already a page mapped at 'va', it is page_remove()d
     - if necesary, on demand, allocates a page table and inserts it 
       into 'pgdir'.
     - pp->pp_ref should be incremented if the insertion succeeds

   returns 0 on success;
   returns -E_NO_MEM, if page table couldn't be allocated */
int page_insert(pde_t *pgdir, struct page *pp, void *va, int perm) 
{
  pde_t *pte;
  cprintf("*** page_insert\n");
  if (pgdir_walk(pgdir, va, 0 /* create */)) {
    cprintf("*** page_remove\n");
    page_remove(pgdir, va);
  }
  cprintf("*** page_insert: pgdir_walk #2\n");
  pte = pgdir_walk(pgdir, va, 1 /* create */);
  if (!pte) {
    cprintf("*** page_insert: NO_MEM #2\n");
    return -E_NO_MEM;
  }
  *pte = (page2pa(pp) << 12) | perm | PTE_P;
  return 0;
}

/* return the page mapped at virtual address 'va'; if ppte is not zero, 
   then we store in it the address of the pte for this page; this is 
   used by page_remove() and can be used to verify page permissions for 
   syscall arguments, but should not be used by most callers

   return 0 if there is no page mapped at va */
struct page *page_lookup(pde_t *pgdir, void *va, pte_t **ppte)
{
  pte_t *pte = pgdir_walk(pgdir, va, 0 /* create */);
  if (pte) {
    *ppte = pte;
    return pa2page(*pte >> 12);
  }
  else 
    return 0;
}

/* unmaps the physical page at virtual address 'va'
   - the ref count on the physical page should decrement
   - the physical page should be freed if the refcount reaches 0
   - the pg table entry corresponding to 'va' should be set to 0
     (if such a PTE exists)
   - the TLB must be invalidated if you remove an entry from the 
     pg dir/pg table */
void page_remove(pde_t *pgdir, void *va)
{
  pte_t *pte;
  struct page *pp = page_lookup(pgdir, va, &pte);
  if (pp) {
    *pte = 0;  
    page_decref(pp);
    tlb_invalidate(pgdir, va);
  }
  else 
    assert(0);
}

/* invalidate a TLB entry, but only if the page tables being edited are 
   the ones currently in use by the processor */
void tlb_invalidate(pde_t *pgdir, void *va)
{
  /* flush the entry only if we're modifying the current address space;
     for now, there is only one address space, so always invalidate */
  invlpg(va);
}

void page_check(void)
{
  struct page *pp, *pp0, *pp1, *pp2;
  struct pagelist fl;
	pte_t *ptep, *ptep1;
	void *va;
	int i;

  /* should be able to allocate three pages */
  pp0 = pp1 = pp2 = 0;
  assert(page_alloc(&pp0) == 0);
  assert(page_alloc(&pp1) == 0);
  assert(page_alloc(&pp2) == 0);
  cprintf("\n=== pp0, pp1, pp2 page_alloc'd\n");
  PRINTMEM("pp0", pp0);
  PRINTMEM("pp1", pp1);
  PRINTMEM("pp2", pp2);

  assert(pp0);
  assert(pp1 && pp1 != pp0);
  assert(pp2 && pp2 != pp1 && pp2 != pp0);

  /* temporarily steal the rest of the free pages */
  fl = page_free_list;
  LIST_INIT(&page_free_list);

  /* should be no free memory */
  assert(page_alloc(&pp) == -E_NO_MEM);

  /* there is no page allocated at address 0 */
  assert(page_lookup(boot_pgdir, (void *) 0x0, &ptep) == NULL);

  /* there is no free memory, so we can't allocate a page table */
  assert(page_insert(boot_pgdir, pp1, 0x0, 0) == -E_NO_MEM);

  /* free pp0 and try again; pp0 should be used for page table */
  page_free(pp0);
  cprintf("=== page_free(pp0) OK1\n");

  assert(page_insert(boot_pgdir, pp1, 0x0, 0) == 0);

  cprintf("OK2\n");

  assert(PTE_ADDR(boot_pgdir[0]) == page2pa(pp0));
  assert(check_va2pa(boot_pgdir, 0x0) == page2pa(pp1));
  assert(pp1->pp_ref == 1);
  assert(pp0->pp_ref == 1);

  /* should be able to map pp2 at PGSIZE because pp0 is already allocated 
     for page table */
  assert(page_insert(boot_pgdir, pp2, (void *) PGSIZE, 0) == 0);
  assert(check_va2pa(boot_pgdir, PGSIZE) == page2pa(pp2));
  assert(pp2->pp_ref == 1);

  /* should be no free memory */
  assert(page_alloc(&pp) == -E_NO_MEM);

  /* should be able to map pp2 at PGSIZE because it's already there */
  assert(page_insert(boot_pgdir, pp2, (void *) PGSIZE, 0) == 0);
  assert(check_va2pa(boot_pgdir, PGSIZE) == page2pa(pp2));
  assert(pp2->pp_ref == 1);

  /* pp2 should NOT be on the free list; could happen in ref counts are
     handled sloppily in page_insert */
  assert(page_alloc(&pp) == -E_NO_MEM);

  /* should not be able to map at PTSIZE because need free page for 
     page table */
  assert(page_insert(boot_pgdir, pp0, (void *) PTSIZE, 0) < 0);

  /* insert pp1 at PGSIZE (replacing pp2) */
  assert(page_insert(boot_pgdir, pp1, (void *) PGSIZE, 0) == 0);

  /* should have pp1 at both 0 and PGSIZE, pp2 nowhere, ... */
  assert(check_va2pa(boot_pgdir, 0x0) == page2pa(pp1));
  assert(check_va2pa(boot_pgdir, PGSIZE) == page2pa(pp1));
 
  /* ... and ref counts should reflect this */
  assert(pp1->pp_ref == 2);
  assert(pp2->pp_ref == 0);

  /* pp2 should be returned by page_alloc */
  assert(page_alloc(&pp) == 0 && pp == pp2);

  /* unmapping pp1 at 0 should keep pp1 at PGSIZE */
  page_remove(boot_pgdir, 0x0);
  assert(check_va2pa(boot_pgdir, 0x0) == ~0);
  assert(check_va2pa(boot_pgdir, PGSIZE) == page2pa(pp1));
  assert(pp1->pp_ref == 1);
  assert(pp2->pp_ref == 0);

  /* unmapping pp1 at PGSIZE should free it */
  page_remove(boot_pgdir, (void *) PGSIZE);
  assert(check_va2pa(boot_pgdir, 0x0) == ~0);
  assert(check_va2pa(boot_pgdir, PGSIZE) == ~0);
  assert(pp1->pp_ref == 0);
  assert(pp2->pp_ref == 0);

  /* so it should be returned by page_alloc */
  assert(page_alloc(&pp) == 0 && pp == pp1);

  /* should be no free memory */
  assert(page_alloc(&pp) == -E_NO_MEM);

  /* forcibly take pp0 back */
  assert(PTE_ADDR(boot_pgdir[0]) == page2pa(pp0));
  boot_pgdir[0] = 0;
  assert(pp0->pp_ref == 1);
  pp0->pp_ref = 0;

	/* check pointer arithmetic in pgdir_walk() */
	page_free(pp0);
	va = (void *) (PGSIZE * NPDENTRIES + PGSIZE);
	ptep = pgdir_walk(boot_pgdir, va, 1);
	ptep1 = KADDR(PTE_ADDR(boot_pgdir[PDX(va)]));
	assert(ptep == ptep1 + PTX(va));
	boot_pgdir[PDX(va)] = 0;
	pp0->pp_ref = 0;
	
	/* check that new page tables get cleared */
	memset(page2kva(pp0), 0xFF, PGSIZE);
	page_free(pp0);
	pgdir_walk(boot_pgdir, 0x0, 1);
	ptep = page2kva(pp0);
	for(i = 0; i < NPTENTRIES; i++)
		assert((ptep[i] & PTE_P) == 0);
	boot_pgdir[0] = 0;
	pp0->pp_ref = 0;

  /* give free list back*/
  page_free_list = fl;

  /* free the pages we took */
  page_free(pp0);
  page_free(pp1);
  page_free(pp2);

  cprintf("page_check() succeeded!\n");
}
